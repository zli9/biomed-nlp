{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cODH2gDaqmu0"
   },
   "source": [
    "\n",
    "# Fine-Tuning of the (Bio-)ELECTRA model on the PubMed RCT 20k dataset\n",
    "\n",
    "Today you will use a modern NLP model, called ELECTRA (**E**fficiently **L**earning an **E**ncoder that **C**lassifies **T**oken **R**eplacements **A**ccurately), for sentence classification of the PubMed 20k RCT dataset.\n",
    "\n",
    "---\n",
    "\n",
    "**BEFORE YOU START:** Change the runtime to GPU (runtime -> change type -> GPU). If you do it at a later point in the notebook, you have to repeat everything.\n",
    "\n",
    "---\n",
    "\n",
    "## Preparations\n",
    "\n",
    "Before you start the training of your model the environment has to be prepared. Therefore the *datasets* and *transformers* packages have to be installed via pip.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1898,
     "status": "ok",
     "timestamp": 1659528568940,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "M8kfiywkxL4P",
    "outputId": "a83578a0-1678-468a-8908-e190f7d80719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
      "/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7424,
     "status": "ok",
     "timestamp": 1659528579909,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "K6XfJikvqV8a",
    "outputId": "9749bf26-9077-4428-f35a-5290dd158574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eL9-NBCUrarU"
   },
   "source": [
    "## Load the data\n",
    "\n",
    "Now that the environment is prepared the data has to be processed. Download the dataset and convert it to a pandas.DataFrame. Use the *from_pandas* function of the [*datasets*](https://huggingface.co/docs/datasets/index.html) package to initialize a dataset containing the train, and test data. Afterward, tokenize the input and assign the correct labels.\n",
    "\n",
    "### Hints\n",
    "\n",
    "*   You will not need spaCy or nltk today\n",
    "*   Check out the [transformers documentation](https://huggingface.co/transformers/) for help\n",
    "*   Use the ElectraTokenizer for tokenization\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Convert the data to a pandas.DataFrame\n",
    "2. Initialize a dataset ([datasets.Dataset.from_pandas](https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Dataset.from_pandas))\n",
    "3. Tokenize the datasets (hint: use the model uri to intialize the tokenizer)\n",
    "4. Generate a numeric representation of the sentence labels (e.g., Background = 0, Methods = 1, ...)\n",
    "5. Specify the output for the dataset (only use 'input_ids', and 'labels'; *hint: look at dataset.set_format()*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1659533309013,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "6G-poPlRsneG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "\n",
    "def convert_to_df(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Convert  documents to DataFrame\n",
    "\n",
    "    Args:\n",
    "\n",
    "        file_path (str): Path to train/dev/test files\n",
    "    \"\"\"\n",
    "    instances = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in tqdm(f.readlines(), desc=f\"Process {file_path}\"):\n",
    "            if line.startswith(\"###\") or len(line.strip()) == 0:\n",
    "                next\n",
    "            else:\n",
    "                label, text = line.split(\"\\t\")\n",
    "                instances.append({\n",
    "                    \"sentence\": text,\n",
    "                    \"label\": label\n",
    "                })\n",
    "    return pd.DataFrame(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1659533311809,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "CXMUccWzygBm"
   },
   "outputs": [],
   "source": [
    "data_dir = '/gdrive/MyDrive/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1116,
     "status": "ok",
     "timestamp": 1659533320231,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "dRX3q8Yuya9d",
    "outputId": "e0afcaaa-3daa-4b31-8b32-409d481d8069"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process /gdrive/MyDrive/data/train.txt: 100%|██████████| 210040/210040 [00:00<00:00, 465049.00it/s]\n",
      "Process /gdrive/MyDrive/data/dev.txt: 100%|██████████| 35212/35212 [00:00<00:00, 916963.64it/s]\n",
      "Process /gdrive/MyDrive/data/test.txt: 100%|██████████| 35135/35135 [00:00<00:00, 950036.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train = convert_to_df(join(data_dir, \"train.txt\"))\n",
    "dev = convert_to_df(join(data_dir, \"dev.txt\"))\n",
    "test = convert_to_df(join(data_dir, \"test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1659533322449,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "ceayBUBE19p7"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "dev['label'] = le.transform(dev['label'])\n",
    "test['label'] = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1659533324326,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "BpmK2soO2aNr",
    "outputId": "7ca7474f-ee01-4e31-d82d-a27e017926be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1659533328544,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "ytv7vf6yy5CJ"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "train_ds = datasets.Dataset.from_pandas(train)\n",
    "dev_ds = datasets.Dataset.from_pandas(dev)\n",
    "test_ds = datasets.Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "add5319d9ccf47899ee8cf1b15efd99f",
      "7869e331efbd4cc290e930360d7d2f36",
      "0d6b771baa0d4d58b88383d7ebb9d770",
      "f82898242e6e43de8c76a490fe5395b3",
      "c63d3d91a11e4a0c9b49b31eb771bff1",
      "c41e469118134ade8563edc16f1d8f19",
      "38c255fe4fb24099b08be5ab8cafde75",
      "748af68a3e9941c4bbf9c0839e75b5b7",
      "09bdeaf7f46d4a4aaffe2fc1e912b957",
      "7ebe766f41184987bea92f24e75ed8fa",
      "fc88c80734d948ef9f052274a6f794bf",
      "df2fbbc321154571b5961da7b8f1fea5",
      "2e0592e0acec49949f232c6069ad5a3f",
      "c4a4d8a79c8e44c2b7a0b08ff76d8565",
      "0a9568916b76487b9b03309db966d6d7",
      "9e3e7b752405477b8cc0f609c3b3aa8a",
      "5ed91c28212448fa8f81ffc6eb4683f2",
      "27b5a4c4412640adbb7a0b76466abe11",
      "7809847f3b2f4af3a3c5a10a85d4e499",
      "db8414326c8a4f7093e2ffd165957250",
      "71335abb67264c7d9eba0c7da5e67e01",
      "29fc84e694724d7797aa94bec097a6d1",
      "af054ed73b2d49bcbd347ba4bb4a2c3b",
      "fdf4550d528c43b7931488a881eae297",
      "d0304626231a4f718978900a27ff9668",
      "958197bdaeb4466b8a56849a3d48e521",
      "d85db34e74ed4014a09252a53c70b713",
      "bfc1ff1a88124e018f88b460c206c262",
      "c748f477d1284a068ca8bfeb68cc2967",
      "146ade52c4ee498f82b4c265c14b26e1",
      "1f773e3aec14419d8717f2201b366fa4",
      "86f82e261b1b46a48ca419ddd3e94d27",
      "5ebb2af2e7aa4057963a4576548fbac5"
     ]
    },
    "executionInfo": {
     "elapsed": 28712,
     "status": "ok",
     "timestamp": 1659533358509,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "Mv_ly-Hz0cks",
    "outputId": "89d5d618-9232-4e0d-8ac6-6c89f371c2b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/electra-small-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ca13c16218c6780ec76753d3afa19fcb7cc759e3f63ee87e441562d374762b3d.3dd1921e571dfa18c0bdaa17b9b38f111097812281989b1cb22263738e66ef73\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-small-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.21.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/ece45ade3e01224cf31fed8e183b306d17b84e8abd415363474cfe72274f7814.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/92992b36de47dee64b1d5a31c05d8d51e3075b918a218f5ba4f6e306c4b81b8c.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/google/electra-small-discriminator/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8b3aea9f7242b3d19268df5b1bfed8f66e08671a72ac0809ada08e5ef1adc592.19eda9a6da5fb0e52a45200c95876729561dde16a69b9116953af6edca1d1e92\n",
      "loading configuration file https://huggingface.co/google/electra-small-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ca13c16218c6780ec76753d3afa19fcb7cc759e3f63ee87e441562d374762b3d.3dd1921e571dfa18c0bdaa17b9b38f111097812281989b1cb22263738e66ef73\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"google/electra-small-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.21.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add5319d9ccf47899ee8cf1b15efd99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2fbbc321154571b5961da7b8f1fea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af054ed73b2d49bcbd347ba4bb4a2c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "\n",
    "def tokenization(example):\n",
    "    return tokenizer(example[\"sentence\"])\n",
    "\n",
    "train_ds = train_ds.map(tokenization, batched=True)\n",
    "dev_ds = dev_ds.map(tokenization, batched=True)\n",
    "test_ds = test_ds.map(tokenization, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1659533360902,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "Sn48EzFz3TjQ"
   },
   "outputs": [],
   "source": [
    "train_ds.set_format(type=\"pt\", columns=[\"input_ids\", \"label\"])\n",
    "dev_ds.set_format(type=\"pt\", columns=[\"input_ids\", \"label\"])\n",
    "test_ds.set_format(type=\"pt\", columns=[\"input_ids\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1659533362582,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "vuHVfTxh4Agy",
    "outputId": "0f85585a-a53c-4d77-80a0-ab091afc2842"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2000,  8556,  1996, 21150,  1997,  1030,  3134,  1997,  3679,\n",
       "          2659,  1011, 13004,  8700,  3653,  2094,  8977, 12898,  2638,  1999,\n",
       "          9229,  3255,  1010, 12969,  1010,  1998, 22575,  2659,  1011,  3694,\n",
       "         21733,  1999,  1996,  2460,  2744,  1998,  3251,  1996,  3466,  2052,\n",
       "          2022,  8760,  2012,  1030,  3134,  1999,  3080,  6001,  2007,  8777,\n",
       "          2000,  5729,  6181,  9808,  2618, 10441, 15265, 14778,  2483,  1006,\n",
       "          1051,  2050,  1007,  1012,   102]), 'label': tensor(3)}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9uofT6iktVDB"
   },
   "source": [
    "## Load the model\n",
    "\n",
    "\n",
    "You will use the ELECTRA-small model as a starting point for the fine-tuning task. The _transformers_ package provides a ElectraForSequenceClassification class which you can use. To do so, you have to specify the number of labels the model should predict.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Load the pre-trained ELECTRA model with the correct number of features to predict\n",
    "  * use the BioELECTRA-small model as a starting point --> the model uri is 'molly-hayward/bioelectra-small-discriminator' (see the [model documentation](https://huggingface.co/molly-hayward/bioelectra-small-discriminator))\n",
    "2. Print the model structure and verify that everything is as expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1659533366760,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "khXrdGiRnhTQ",
    "outputId": "e47abc1c-4b30-4550-a50a-e3f8cba666e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug  3 13:29:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   58C    P0    29W /  70W |   4008MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1659533369159,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "Hei-4Rm7uRhu",
    "outputId": "0ba18ba7-a0b6-44a7-8afc-a577b24dbe56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/electra-small-discriminator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ca13c16218c6780ec76753d3afa19fcb7cc759e3f63ee87e441562d374762b3d.3dd1921e571dfa18c0bdaa17b9b38f111097812281989b1cb22263738e66ef73\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.21.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/electra-small-discriminator/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1ebdea26ed1a6268cdf5d1fe36450e89c70e306c97d39e62ede8a31f1c43f9ad.baa63624f08a59503441bce3d427225c61fe79bfa9f6d4c30cde7d072d863e0c\n",
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=256, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraForSequenceClassification, ElectraConfig\n",
    "\n",
    "config=ElectraConfig.from_pretrained(\"google/electra-small-discriminator\")\n",
    "config.num_labels=5\n",
    "electra_small = ElectraForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\", config=config)\n",
    "\n",
    "print(electra_small)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xkdn61U4u9MD"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Train the model using the [Trainer class](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Trainer) of the transformers package. First, specify the training arguments (check [the documentation](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments) for a complete overview of the options) and then start the training.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1.   Specify suitable [training arguments](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments) -> check out what the authors of the [ELECTRA paper](https://openreview.net/pdf?id=r1xMH1BtvB) used\n",
    "2.   Implement a function that computes evaluation metrics during training\n",
    "  * What metric could be used?\n",
    "  * Look at the *compute_metrics* argument of the *Trainer* class\n",
    "  * The function should take an [EvalPrediction](https://huggingface.co/transformers/internal/trainer_utils.html#transformers.EvalPrediction) as input and return a Dict with the metric names and values \n",
    "3.   Start the training (**verify that it runs on GPU**)\n",
    "  * Pass the specified training arguments to the trainer\n",
    "  * Pass the implemented metric function and evaluate on the test set during training\n",
    "4. Optional: Use an [early stopping callback](https://huggingface.co/transformers/main_classes/callback.html#transformers.EarlyStoppingCallback) instead of a fixed number of epochs (hint: you need the dev set for that)\n",
    "4. Optional: You can save and download the pretrained model --> if your instance stops, you can load the model again without training\n",
    "5. Optional: Use mlflow to log, for instance, metrics during training\n",
    "  * Save the data to a local folder (e.g., mlruns/) and access it later on using [this script](https://colab.research.google.com/drive/1dwQOZBPjcIPydyFYjJ_EN2oC0Go1KmM-?usp=sharing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1659533374503,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "SUfTuZ6MEYIk",
    "outputId": "3383154a-de42-49a2-f702-b0aab9d44af0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments for training\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "learning_rate = 3e-4\n",
    "adam_epsilon = 1e-6\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.1\n",
    "weight_decay = 0\n",
    "per_device_train_batch_size = 32\n",
    "num_train_epochs = 3\n",
    "\n",
    "targs = TrainingArguments(output_dir=data_dir, \n",
    "                          learning_rate=learning_rate, \n",
    "                          adam_epsilon=adam_epsilon, \n",
    "                          adam_beta1=adam_beta1, \n",
    "                          adam_beta2=adam_beta2, \n",
    "                          lr_scheduler_type=lr_scheduler_type,\n",
    "                          warmup_ratio=warmup_ratio,\n",
    "                          weight_decay=weight_decay,\n",
    "                          per_device_train_batch_size=per_device_train_batch_size,\n",
    "                          num_train_epochs=num_train_epochs,\n",
    "                          evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1659533376572,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "SmbZ8A1Cw_as"
   },
   "outputs": [],
   "source": [
    "# Define compute_metric function for evaluation\n",
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "from typing import Dict\n",
    "\n",
    "def compute_metrics(prediction: EvalPrediction) -> Dict[str, float]:\n",
    "  # TODO: implement evaluation function\n",
    "  logits, labels = prediction\n",
    "  pred = np.argmax(logits, axis=-1)\n",
    "  acc = datasets.load_metric('accuracy').compute(predictions=pred, references=labels)['accuracy']\n",
    "  f1 = datasets.load_metric('f1').compute(predictions=pred, references=labels, average='micro')['f1']\n",
    "  recall = datasets.load_metric('recall').compute(predictions=pred, references=labels, average='micro')['recall']\n",
    "  return {\n",
    "      \"accuracy\": acc,\n",
    "      \"f1-score\": f1,\n",
    "      \"recall\": recall\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1659533386262,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "7lphHX9sKLMW"
   },
   "outputs": [],
   "source": [
    "# Instantiate Trainer Class\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = electra_small,\n",
    "    args= targs,\n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset = dev_ds,\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2180352,
     "status": "ok",
     "timestamp": 1659535569143,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "HLlXBklUmEPa",
    "outputId": "0866e6ce-4e94-4f37-9720-4361a0273a93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence. If sentence are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 180040\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16881' max='16881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16881/16881 36:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.505900</td>\n",
       "      <td>0.465720</td>\n",
       "      <td>0.833311</td>\n",
       "      <td>0.833311</td>\n",
       "      <td>0.833311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>0.414788</td>\n",
       "      <td>0.848669</td>\n",
       "      <td>0.848669</td>\n",
       "      <td>0.848669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.394266</td>\n",
       "      <td>0.860817</td>\n",
       "      <td>0.860817</td>\n",
       "      <td>0.860817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-1000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-1000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-1500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-1500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-2000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-2000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-2500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-2500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-3000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-3000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-3500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-3500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-4000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-4000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-4500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-4500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-5000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-5000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-5500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-5500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-5500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence. If sentence are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30212\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-6000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-6000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-6500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-6500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-6500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-7000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-7000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-7500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-7500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-8000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-8000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-8500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-8500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-9000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-9000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-9500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-9500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-9500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-10000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-10000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-10000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-10500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-10500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-10500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-11000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-11000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-11000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence. If sentence are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30212\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-11500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-11500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-11500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-12000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-12000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-12500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-12500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-12500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-13000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-13000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-13000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-13500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-13500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-13500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-14000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-14000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-14500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-14500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-14500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-15000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-15000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-15000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-15500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-15500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-15500/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-16000\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-16000/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to /gdrive/MyDrive/data/checkpoint-16500\n",
      "Configuration saved in /gdrive/MyDrive/data/checkpoint-16500/config.json\n",
      "Model weights saved in /gdrive/MyDrive/data/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in /gdrive/MyDrive/data/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in /gdrive/MyDrive/data/checkpoint-16500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence. If sentence are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30212\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16881, training_loss=0.4721238908168299, metrics={'train_runtime': 2179.9312, 'train_samples_per_second': 247.769, 'train_steps_per_second': 7.744, 'total_flos': 3021686331518400.0, 'train_loss': 0.4721238908168299, 'epoch': 3.0})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "X0PsSY0hw_5f"
   },
   "source": [
    "## Evaluate your model\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Run predictions on the test dataset\n",
    "2. Optional: Generate a plot with the train/eval loss over time (manually or with mlflow)\n",
    "3. Calculate the average and class-wise F1 scores (look at sklearn.metrics.classification_report)\n",
    "\n",
    "When you are finished with the tasks, repeat the training and evaluation for the ELECTRA-small model from Google (huggingface model uri = 'google/electra-small-discriminator') and compare its performance to the BioELECTRA-small model. If there is no time left, you do not have to do this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 81065,
     "status": "ok",
     "timestamp": 1659535986139,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "ygvEFmgivEG9",
    "outputId": "da31959d-a5b6-44dd-c798-93e098001143"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence. If sentence are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 30135\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predition = trainer.predict(test_dataset = test_ds)\n",
    "y_pred = np.argmax(predition.predictions, axis = 1)\n",
    "y_true = predition.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1659536065665,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "mJb_6R_2CSLR",
    "outputId": "51eac3d5-cdf5-453f-a823-7cd00cd3b121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.68      0.75      0.71      3621\n",
      " CONCLUSIONS       0.81      0.79      0.80      4571\n",
      "     METHODS       0.91      0.94      0.92      9897\n",
      "   OBJECTIVE       0.74      0.57      0.64      2333\n",
      "     RESULTS       0.91      0.90      0.90      9713\n",
      "\n",
      "    accuracy                           0.85     30135\n",
      "   macro avg       0.81      0.79      0.80     30135\n",
      "weighted avg       0.85      0.85      0.85     30135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = list(le.classes_)\n",
    "print(classification_report(y_true, y_pred, target_names = target_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R7cw_jaUxnrv"
   },
   "source": [
    "## Visualizations\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Visualize the calcultated metrics (e.g., with a barplot)\n",
    "2. Optional: Generate a tSNE visualization of the ELECTRA representations and use the sentence label for coloring\n",
    "  * You need the output of the base model --> Initialize the transformers.ElectraModel with the weights of your fine-tuned model\n",
    "  * Pass the test data through the model and use the *last_hidden_state* that is returned by the model (see the [documentation](https://huggingface.co/transformers/model_doc/electra.html#transformers.ElectraModel.forward))\n",
    "  * Use sklearn.manifold.TSNE to calculate 2 tSNE components\n",
    "  * Visualize the representation in a scatterplot (e.g., look at seaborn.scatterplot) and use the sentence labels as color\n",
    "3. Optional: Generate a PCA visualization for the ELECTRA representations and compare it to the tSNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1659537172344,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "380xVocgEhYM",
    "outputId": "859a6c81-4340-4443-c87d-0bf0a6a11cbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0301b793-d679-44d8-b5ae-1fe327fd2946\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676692</td>\n",
       "      <td>0.745650</td>\n",
       "      <td>0.709499</td>\n",
       "      <td>3621.0</td>\n",
       "      <td>BACKGROUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.809821</td>\n",
       "      <td>0.793699</td>\n",
       "      <td>0.801679</td>\n",
       "      <td>4571.0</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909953</td>\n",
       "      <td>0.940386</td>\n",
       "      <td>0.924919</td>\n",
       "      <td>9897.0</td>\n",
       "      <td>METHODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.739855</td>\n",
       "      <td>0.570510</td>\n",
       "      <td>0.644240</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.908280</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.904759</td>\n",
       "      <td>9713.0</td>\n",
       "      <td>RESULTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0301b793-d679-44d8-b5ae-1fe327fd2946')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0301b793-d679-44d8-b5ae-1fe327fd2946 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0301b793-d679-44d8-b5ae-1fe327fd2946');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   precision    recall  f1-score  support        label\n",
       "0   0.676692  0.745650  0.709499   3621.0   BACKGROUND\n",
       "1   0.809821  0.793699  0.801679   4571.0  CONCLUSIONS\n",
       "2   0.909953  0.940386  0.924919   9897.0      METHODS\n",
       "3   0.739855  0.570510  0.644240   2333.0    OBJECTIVE\n",
       "4   0.908280  0.901266  0.904759   9713.0      RESULTS"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(classification_report(y_true, y_pred, output_dict=True)).transpose()[:5]\n",
    "df['label'] = list(le.classes_)\n",
    "df\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1659537316282,
     "user": {
      "displayName": "Zexin Li",
      "userId": "15130272191425633670"
     },
     "user_tz": -120
    },
    "id": "QTrIlcu-1NSL",
    "outputId": "0c911bfd-0e02-4f2d-9a90-088046949b16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Model Evaluation: ELECTRA-small')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.barplot(x='label', y='f1-score', data=df)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "plt.title(\"Model Evaluation: ELECTRA-small\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "d3_sentence_classification_with_electra.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09bdeaf7f46d4a4aaffe2fc1e912b957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a9568916b76487b9b03309db966d6d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71335abb67264c7d9eba0c7da5e67e01",
      "placeholder": "​",
      "style": "IPY_MODEL_29fc84e694724d7797aa94bec097a6d1",
      "value": " 31/31 [00:03&lt;00:00, 11.61ba/s]"
     }
    },
    "0d6b771baa0d4d58b88383d7ebb9d770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_748af68a3e9941c4bbf9c0839e75b5b7",
      "max": 181,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09bdeaf7f46d4a4aaffe2fc1e912b957",
      "value": 181
     }
    },
    "146ade52c4ee498f82b4c265c14b26e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f773e3aec14419d8717f2201b366fa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27b5a4c4412640adbb7a0b76466abe11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29fc84e694724d7797aa94bec097a6d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e0592e0acec49949f232c6069ad5a3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ed91c28212448fa8f81ffc6eb4683f2",
      "placeholder": "​",
      "style": "IPY_MODEL_27b5a4c4412640adbb7a0b76466abe11",
      "value": "100%"
     }
    },
    "38c255fe4fb24099b08be5ab8cafde75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ebb2af2e7aa4057963a4576548fbac5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ed91c28212448fa8f81ffc6eb4683f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71335abb67264c7d9eba0c7da5e67e01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "748af68a3e9941c4bbf9c0839e75b5b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7809847f3b2f4af3a3c5a10a85d4e499": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7869e331efbd4cc290e930360d7d2f36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c41e469118134ade8563edc16f1d8f19",
      "placeholder": "​",
      "style": "IPY_MODEL_38c255fe4fb24099b08be5ab8cafde75",
      "value": "100%"
     }
    },
    "7ebe766f41184987bea92f24e75ed8fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86f82e261b1b46a48ca419ddd3e94d27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "958197bdaeb4466b8a56849a3d48e521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86f82e261b1b46a48ca419ddd3e94d27",
      "placeholder": "​",
      "style": "IPY_MODEL_5ebb2af2e7aa4057963a4576548fbac5",
      "value": " 31/31 [00:03&lt;00:00, 10.55ba/s]"
     }
    },
    "9e3e7b752405477b8cc0f609c3b3aa8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "add5319d9ccf47899ee8cf1b15efd99f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7869e331efbd4cc290e930360d7d2f36",
       "IPY_MODEL_0d6b771baa0d4d58b88383d7ebb9d770",
       "IPY_MODEL_f82898242e6e43de8c76a490fe5395b3"
      ],
      "layout": "IPY_MODEL_c63d3d91a11e4a0c9b49b31eb771bff1"
     }
    },
    "af054ed73b2d49bcbd347ba4bb4a2c3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fdf4550d528c43b7931488a881eae297",
       "IPY_MODEL_d0304626231a4f718978900a27ff9668",
       "IPY_MODEL_958197bdaeb4466b8a56849a3d48e521"
      ],
      "layout": "IPY_MODEL_d85db34e74ed4014a09252a53c70b713"
     }
    },
    "bfc1ff1a88124e018f88b460c206c262": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c41e469118134ade8563edc16f1d8f19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4a4d8a79c8e44c2b7a0b08ff76d8565": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7809847f3b2f4af3a3c5a10a85d4e499",
      "max": 31,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db8414326c8a4f7093e2ffd165957250",
      "value": 31
     }
    },
    "c63d3d91a11e4a0c9b49b31eb771bff1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c748f477d1284a068ca8bfeb68cc2967": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0304626231a4f718978900a27ff9668": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_146ade52c4ee498f82b4c265c14b26e1",
      "max": 31,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f773e3aec14419d8717f2201b366fa4",
      "value": 31
     }
    },
    "d85db34e74ed4014a09252a53c70b713": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db8414326c8a4f7093e2ffd165957250": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df2fbbc321154571b5961da7b8f1fea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e0592e0acec49949f232c6069ad5a3f",
       "IPY_MODEL_c4a4d8a79c8e44c2b7a0b08ff76d8565",
       "IPY_MODEL_0a9568916b76487b9b03309db966d6d7"
      ],
      "layout": "IPY_MODEL_9e3e7b752405477b8cc0f609c3b3aa8a"
     }
    },
    "f82898242e6e43de8c76a490fe5395b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ebe766f41184987bea92f24e75ed8fa",
      "placeholder": "​",
      "style": "IPY_MODEL_fc88c80734d948ef9f052274a6f794bf",
      "value": " 181/181 [00:19&lt;00:00, 12.28ba/s]"
     }
    },
    "fc88c80734d948ef9f052274a6f794bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdf4550d528c43b7931488a881eae297": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfc1ff1a88124e018f88b460c206c262",
      "placeholder": "​",
      "style": "IPY_MODEL_c748f477d1284a068ca8bfeb68cc2967",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
